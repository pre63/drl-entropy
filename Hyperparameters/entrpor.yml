Pendulum-v1:
  policy: 'MlpPolicy'
  n_envs: 10
  n_timesteps: 100000
  reward_threshold: -3.0
  normalize: true
  n_steps: 1024
  n_critic_updates: 20

# Tuned
LunarLanderContinuous-v3:
  policy: 'MlpPolicy'
  n_envs: 10
  n_timesteps: 100000
  reward_threshold: 195
  ent_coef: 0.0008
  gamma: 0.9949027914528422
  gae_lambda: 0.906
  target_kl: 0.003
  cg_damping: 0.01
  cg_max_steps: 18
  line_search_max_iter: 10
  n_steps: 2048
  batch_size: 256

# Tuned
Ant-v5:
  policy: 'MlpPolicy'
  n_envs: 10
  n_timesteps: 100000
  reward_threshold: 1000
  ent_coef: 0.0002
  gamma: 0.9847991092894313
  gae_lambda: 0.982
  target_kl: 0.001
  cg_damping: 0.09
  cg_max_steps: 10
  line_search_max_iter: 10
  n_steps: 4096
  batch_size: 96

# Tuned
Humanoid-v5:
  policy: 'MlpPolicy'
  n_envs: 10
  n_timesteps: 100000
  n_steps: 256
  gamma: 0.9999
  learning_rate: 0.001981986604251018
  n_critic_updates: 5
  cg_max_steps: 20
  target_kl: 0.03
  gae_lambda: 0.8
  net_arch: small
  activation_fn: tanh
  batch_size: 16
  ent_coef: 0.0005
  reward_threshold: 450

# Tuned
InvertedDoublePendulum-v5:
  policy: 'MlpPolicy'
  n_envs: 10
  n_timesteps: 100000
  reward_threshold: 410
  ent_coef: 0.0
  gamma: 0.9895010605462053
  gae_lambda: 0.9650000000000001
  target_kl: 0.003
  cg_damping: 0.06999999999999999
  cg_max_steps: 10
  line_search_max_iter: 15
  n_steps: 4096
  batch_size: 256

# Tuned
RocketLander-v0:
  policy: 'MlpPolicy'
  n_envs: 10
  n_timesteps: 100000
  reward_threshold: -3.0
  ent_coef: 0.0001
  gamma: 0.9906622621965028
  gae_lambda: 0.983
  target_kl: 0.013000000000000001
  cg_damping: 0.09
  cg_max_steps: 19
  line_search_max_iter: 15
  n_steps: 1024
  batch_size: 192
