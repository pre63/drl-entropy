# Tuned
Pendulum-v1:
  policy: "MlpPolicy"
  n_timesteps: 100000
  reward_threshold: -3.0
  n_envs: 4
  n_steps: 1024
  gae_lambda: 0.95
  gamma: 0.9
  n_epochs: 10
  ent_coef: 0.0
  learning_rate: !!float 1e-3
  clip_range: 0.2
  use_sde: True
  sde_sample_freq: 4

# Tuned
LunarLanderContinuous-v3:
  policy: "MlpPolicy"
  n_timesteps: 100000
  reward_threshold: 195
  n_envs: 16
  n_timesteps: !!float 1e6
  policy: 'MlpPolicy'
  n_steps: 1024
  batch_size: 64
  gae_lambda: 0.98
  gamma: 0.999
  n_epochs: 4
  ent_coef: 0.01

Ant-v5:
  policy: "MlpPolicy"
  batch_size: 64
  n_steps: 256
  gamma: 0.9
  learning_rate: 0.011345042877629868
  ent_coef: 0.0006300346375901035
  clip_range: 0.3
  n_epochs: 1
  gae_lambda: 0.99
  max_grad_norm: 0.3
  vf_coef: 0.9467710647343072
  net_arch: small
  activation_fn: relu
  n_timesteps: 100000
  n_envs: 10

# Tuned
Humanoid-v5:
  policy: "MlpPolicy"
  batch_size: 32
  n_steps: 16
  gamma: 0.9999
  learning_rate: 0.0006183509029833883
  ent_coef: 4.222709699945666e-06
  clip_range: 0.3
  n_epochs: 1
  gae_lambda: 0.99
  max_grad_norm: 0.9
  vf_coef: 0.35158850327788066
  net_arch: medium
  activation_fn: tanh
  n_timesteps: 400000
  n_envs: 10

# Tuned
InvertedDoublePendulum-v5:
  policy: "MlpPolicy"
  batch_size: 256
  n_steps: 512
  gamma: 0.95
  learning_rate: 0.008853701642334575
  ent_coef: 2.5370668529088744e-08
  clip_range: 0.1
  n_epochs: 10
  gae_lambda: 0.8
  max_grad_norm: 0.3
  vf_coef: 0.6300195360697247
  net_arch: tiny
  activation_fn: tanh
  n_timesteps: 100000
  n_envs: 4

RocketLander-v0:
  policy: "MlpPolicy"
  n_timesteps: 100000
  reward_threshold: -3.0