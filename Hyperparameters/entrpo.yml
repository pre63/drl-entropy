Pendulum-v1:
  policy: "MlpPolicy"
  n_timesteps: 100000
  reward_threshold: -3

# Tuned
LunarLanderContinuous-v3:
  policy: "MlpPolicy"
  n_timesteps: 100000
  reward_threshold: 300
  n_steps: 2048
  gamma: 0.99
  learning_rate: 0.0014690394043123287
  n_critic_updates: 20
  cg_max_steps: 25
  target_kl: 0.05
  gae_lambda: 0.95
  batch_size: 256
  net_arch: medium
  activation_fn: tanh
  ent_coef: 0.0009000000000000001
  buffer_capacity: 20000
  replay_strategy_threshold: -4.105715891723701
  epsilon: 0.4
  n_envs: 8

# Tuned
Ant-v5:
  policy: "MlpPolicy"
  n_steps: 512
  gamma: 0.99
  learning_rate: 0.0009783065937853852
  n_critic_updates: 10
  cg_max_steps: 30
  target_kl: 0.01
  gae_lambda: 0.8
  batch_size: 512
  net_arch: medium
  activation_fn: tanh
  ent_coef: 0.00030000000000000003
  buffer_capacity: 3000
  reward_threshold: 300
  replay_strategy_threshold: -2.918898840377884
  epsilon: 0.4
  use_per: 1
  orthogonal_init: 0
  n_timesteps: 1000000
  n_envs: 8

# Tuned
Humanoid-v5:
  policy: "MlpPolicy"
  n_timesteps: 100000
  reward_threshold: 450
  batch_size: 256
  n_steps: 256
  gamma: 0.999
  learning_rate: 0.0013728588534608977
  n_critic_updates: 10
  cg_max_steps: 20
  target_kl: 0.02
  gae_lambda: 1
  net_arch: small
  activation_fn: tanh
  n_envs: 8



# Tuned
InvertedDoublePendulum-v5:
  policy: "MlpPolicy"
  n_steps: 128
  gamma: 0.99
  learning_rate: 0.0006311544569794092
  n_critic_updates: 10
  cg_max_steps: 25
  target_kl: 0.005
  gae_lambda: 1
  batch_size: 32
  net_arch: small
  activation_fn: relu
  ent_coef: 0.0009000000000000001
  buffer_capacity: 35000
  reward_threshold: 500
  replay_strategy_threshold: -1.3755325643060332
  epsilon: 0.25
  use_per: 1
  orthogonal_init: 1
  n_timesteps: 100000
  n_envs: 2

# Tuned
RocketLander-v0:
  policy: "MlpPolicy"
  n_timesteps: 100000
  n_steps: 64
  gamma: 0.9
  learning_rate: 0.10395269858305548
  n_critic_updates: 5
  cg_max_steps: 10
  target_kl: 0.02
  gae_lambda: 0.95
  batch_size: 256
  net_arch: small
  activation_fn: tanh
  ent_coef: 0
  buffer_capacity: 30000
  reward_threshold: 200
  replay_strategy_threshold: -3.323593843864824
  epsilon: 0.75
