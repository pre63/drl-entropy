Ant-v5:
  trial_number: 115
  value: 2919.2788072
  params:
    n_steps: 64
    gamma: 0.99
    learning_rate: 0.00010513747606756011
    n_critic_updates: 30
    cg_max_steps: 10
    target_kl: 0.001
    gae_lambda: 0.8
    batch_size: 32
    net_arch: small
    activation_fn: tanh
    ent_coef: 0.0007
    buffer_capacity: 99000
    reward_threshold: 200
    replay_strategy_threshold: 6.687471761814196
    epsilon: 0.30000000000000004
    use_per: 0
    orthogonal_init: 0
    n_timesteps: 800000
    n_envs: 4
  comment: 'Best trial details: _number=115, state=1, _values=[2919.2788072], _datetime_start=2025-01-29
    00:19:49.845594, datetime_complete=2025-01-29 14:39:14.597792, _params={''n_steps'':
    64, ''gamma'': 0.99, ''learning_rate'': 0.00010513747606756011, ''n_critic_updates'':
    30, ''cg_max_steps'': 10, ''target_kl'': 0.001, ''gae_lambda'': 0.8, ''batch_size'':
    32, ''net_arch'': ''small'', ''activation_fn'': ''tanh'', ''ent_coef'': 0.0007,
    ''buffer_capacity'': 99000, ''reward_threshold'': 200.0, ''replay_strategy_threshold'':
    6.687471761814196, ''epsilon'': 0.30000000000000004, ''use_per'': False, ''orthogonal_init'':
    False, ''n_timesteps'': 800000, ''n_envs'': 4}, _user_attrs={}, _system_attrs={''completed_rung_0'':
    2100.1257321999997}, intermediate_values={1: 2100.1257321999997, 2: 2919.2788072},
    _distributions={''n_steps'': CategoricalDistribution(choices=(8, 16, 32, 64, 128,
    256, 512, 1024, 2048)), ''gamma'': CategoricalDistribution(choices=(0.8, 0.85,
    0.9, 0.95, 0.99)), ''learning_rate'': FloatDistribution(high=1.0, log=True, low=1e-05,
    step=None), ''n_critic_updates'': CategoricalDistribution(choices=(5, 10, 20,
    25, 30)), ''cg_max_steps'': CategoricalDistribution(choices=(5, 10, 20, 25, 30)),
    ''target_kl'': CategoricalDistribution(choices=(0.1, 0.05, 0.03, 0.02, 0.01, 0.005,
    0.001)), ''gae_lambda'': CategoricalDistribution(choices=(0.8, 0.9, 0.92, 0.95,
    0.98, 0.99, 1.0)), ''batch_size'': CategoricalDistribution(choices=(8, 16, 32,
    64, 128, 256, 512, 1024)), ''net_arch'': CategoricalDistribution(choices=(''small'',
    ''medium'')), ''activation_fn'': CategoricalDistribution(choices=(''tanh'', ''relu'')),
    ''ent_coef'': FloatDistribution(high=0.001, log=False, low=0.0, step=0.0001),
    ''buffer_capacity'': IntDistribution(high=100000, log=False, low=1000, step=1000),
    ''reward_threshold'': FloatDistribution(high=500.0, log=False, low=200.0, step=50.0),
    ''replay_strategy_threshold'': FloatDistribution(high=10.0, log=False, low=-10.0,
    step=None), ''epsilon'': FloatDistribution(high=0.9, log=False, low=0.1, step=0.05),
    ''use_per'': CategoricalDistribution(choices=(True, False)), ''orthogonal_init'':
    CategoricalDistribution(choices=(True, False)), ''n_timesteps'': IntDistribution(high=1000000,
    log=False, low=100000, step=100000), ''n_envs'': CategoricalDistribution(choices=(2,
    4, 6, 8, 10))}, _trial_id=115'
InvertedDoublePendulum-v5:
  trial_number: 45
  value: 418.48607359999994
  params:
    n_steps: 8
    gamma: 0.9
    learning_rate: 9.130248590964833e-05
    n_critic_updates: 5
    cg_max_steps: 5
    target_kl: 0.03
    gae_lambda: 0.9
    batch_size: 512
    net_arch: small
    activation_fn: relu
    ent_coef: 0.0007
    buffer_capacity: 90000
    reward_threshold: 300
    replay_strategy_threshold: -6.445230494093042
    epsilon: 0.5
    use_per: 1
    orthogonal_init: 1
    n_timesteps: 400000
    n_envs: 6
  comment: 'Best trial details: _number=45, state=2, _values=[418.48607359999994],
    _datetime_start=2025-02-02 22:51:56.622948, datetime_complete=2025-02-02 23:50:51.133892,
    _params={''n_steps'': 8, ''gamma'': 0.9, ''learning_rate'': 9.130248590964833e-05,
    ''n_critic_updates'': 5, ''cg_max_steps'': 5, ''target_kl'': 0.03, ''gae_lambda'':
    0.9, ''batch_size'': 512, ''net_arch'': ''small'', ''activation_fn'': ''relu'',
    ''ent_coef'': 0.0007, ''buffer_capacity'': 90000, ''reward_threshold'': 300.0,
    ''replay_strategy_threshold'': -6.445230494093042, ''epsilon'': 0.5, ''use_per'':
    True, ''orthogonal_init'': True, ''n_timesteps'': 400000, ''n_envs'': 6}, _user_attrs={},
    _system_attrs={''completed_rung_0'': 418.48607359999994}, intermediate_values={1:
    418.48607359999994}, _distributions={''n_steps'': CategoricalDistribution(choices=(8,
    16, 32, 64, 128, 256, 512, 1024, 2048)), ''gamma'': CategoricalDistribution(choices=(0.8,
    0.85, 0.9, 0.95, 0.99)), ''learning_rate'': FloatDistribution(high=1.0, log=True,
    low=1e-05, step=None), ''n_critic_updates'': CategoricalDistribution(choices=(5,
    10, 20, 25, 30)), ''cg_max_steps'': CategoricalDistribution(choices=(5, 10, 20,
    25, 30)), ''target_kl'': CategoricalDistribution(choices=(0.1, 0.05, 0.03, 0.02,
    0.01, 0.005, 0.001)), ''gae_lambda'': CategoricalDistribution(choices=(0.8, 0.9,
    0.92, 0.95, 0.98, 0.99, 1.0)), ''batch_size'': CategoricalDistribution(choices=(8,
    16, 32, 64, 128, 256, 512, 1024)), ''net_arch'': CategoricalDistribution(choices=(''small'',
    ''medium'')), ''activation_fn'': CategoricalDistribution(choices=(''tanh'', ''relu'')),
    ''ent_coef'': FloatDistribution(high=0.001, log=False, low=0.0, step=0.0001),
    ''buffer_capacity'': IntDistribution(high=100000, log=False, low=1000, step=1000),
    ''reward_threshold'': FloatDistribution(high=500.0, log=False, low=200.0, step=50.0),
    ''replay_strategy_threshold'': FloatDistribution(high=10.0, log=False, low=-10.0,
    step=None), ''epsilon'': FloatDistribution(high=0.9, log=False, low=0.1, step=0.05),
    ''use_per'': CategoricalDistribution(choices=(True, False)), ''orthogonal_init'':
    CategoricalDistribution(choices=(True, False)), ''n_timesteps'': IntDistribution(high=1000000,
    log=False, low=100000, step=100000), ''n_envs'': CategoricalDistribution(choices=(2,
    4, 6, 8, 10))}, _trial_id=45'
