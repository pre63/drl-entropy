Ant-v5:
  trial_number: 690
  value: 5153.545104
  params:
    n_steps: 512.0
    gamma: 0.99
    learning_rate: 0.0009783065937853852
    n_critic_updates: 10.0
    cg_max_steps: 30.0
    target_kl: 0.01
    gae_lambda: 0.8
    batch_size: 512.0
    net_arch: medium
    activation_fn: tanh
    ent_coef: 0.00030000000000000003
    buffer_capacity: 3000.0
    reward_threshold: 300.0
    replay_strategy_threshold: -2.918898840377884
    epsilon: 0.4
    use_per: 1.0
    orthogonal_init: 0.0
    n_timesteps: 1000000.0
    n_envs: 8.0
  comment: 'Best trial value: 5153.545104, params: {''n_steps'': 512, ''gamma'': 0.99,
    ''learning_rate'': 0.0009783065937853852, ''n_critic_updates'': 10, ''cg_max_steps'':
    30, ''target_kl'': 0.01, ''gae_lambda'': 0.8, ''batch_size'': 512, ''net_arch'':
    ''medium'', ''activation_fn'': ''tanh'', ''ent_coef'': 0.00030000000000000003,
    ''buffer_capacity'': 3000, ''reward_threshold'': 300.0, ''replay_strategy_threshold'':
    -2.918898840377884, ''epsilon'': 0.4, ''use_per'': True, ''orthogonal_init'':
    False, ''n_timesteps'': 1000000, ''n_envs'': 8}'
InvertedDoublePendulum-v5:
  trial_number: 86
  value: 9359.130448799999
  params:
    n_steps: 128
    gamma: 0.99
    learning_rate: 0.0006311544569794092
    n_critic_updates: 10
    cg_max_steps: 25
    target_kl: 0.005
    gae_lambda: 1
    batch_size: 32
    net_arch: small
    activation_fn: relu
    ent_coef: 0.0009000000000000001
    buffer_capacity: 35000
    reward_threshold: 500
    replay_strategy_threshold: -1.3755325643060332
    epsilon: 0.25
    use_per: 1
    orthogonal_init: 1
    n_timesteps: 100000
    n_envs: 2
  comment: 'Best trial details: _number=86, state=1, _values=[9359.130448799999],
    _datetime_start=2025-01-30 19:13:16.728360, datetime_complete=2025-01-30 20:00:44.763013,
    _params={''n_steps'': 128, ''gamma'': 0.99, ''learning_rate'': 0.0006311544569794092,
    ''n_critic_updates'': 10, ''cg_max_steps'': 25, ''target_kl'': 0.005, ''gae_lambda'':
    1.0, ''batch_size'': 32, ''net_arch'': ''small'', ''activation_fn'': ''relu'',
    ''ent_coef'': 0.0009000000000000001, ''buffer_capacity'': 35000, ''reward_threshold'':
    500.0, ''replay_strategy_threshold'': -1.3755325643060332, ''epsilon'': 0.25,
    ''use_per'': True, ''orthogonal_init'': True, ''n_timesteps'': 100000, ''n_envs'':
    2}, _user_attrs={}, _system_attrs={''completed_rung_0'': 9359.592525199998}, intermediate_values={1:
    9359.592525199998, 2: 9359.130448799999}, _distributions={''n_steps'': CategoricalDistribution(choices=(8,
    16, 32, 64, 128, 256, 512, 1024, 2048)), ''gamma'': CategoricalDistribution(choices=(0.8,
    0.85, 0.9, 0.95, 0.99)), ''learning_rate'': FloatDistribution(high=1.0, log=True,
    low=1e-05, step=None), ''n_critic_updates'': CategoricalDistribution(choices=(5,
    10, 20, 25, 30)), ''cg_max_steps'': CategoricalDistribution(choices=(5, 10, 20,
    25, 30)), ''target_kl'': CategoricalDistribution(choices=(0.1, 0.05, 0.03, 0.02,
    0.01, 0.005, 0.001)), ''gae_lambda'': CategoricalDistribution(choices=(0.8, 0.9,
    0.92, 0.95, 0.98, 0.99, 1.0)), ''batch_size'': CategoricalDistribution(choices=(8,
    16, 32, 64, 128, 256, 512, 1024)), ''net_arch'': CategoricalDistribution(choices=(''small'',
    ''medium'')), ''activation_fn'': CategoricalDistribution(choices=(''tanh'', ''relu'')),
    ''ent_coef'': FloatDistribution(high=0.001, log=False, low=0.0, step=0.0001),
    ''buffer_capacity'': IntDistribution(high=100000, log=False, low=1000, step=1000),
    ''reward_threshold'': FloatDistribution(high=500.0, log=False, low=200.0, step=50.0),
    ''replay_strategy_threshold'': FloatDistribution(high=10.0, log=False, low=-10.0,
    step=None), ''epsilon'': FloatDistribution(high=0.9, log=False, low=0.1, step=0.05),
    ''use_per'': CategoricalDistribution(choices=(True, False)), ''orthogonal_init'':
    CategoricalDistribution(choices=(True, False)), ''n_timesteps'': IntDistribution(high=1000000,
    log=False, low=100000, step=100000), ''n_envs'': CategoricalDistribution(choices=(2,
    4, 6, 8, 10))}, _trial_id=86'
Pendulum-v1:
  trial_number: 24
  value: -138.3224832
  params:
    n_steps: 64
    gamma: 0.9
    learning_rate: 0.004587560343239131
    n_critic_updates: 10
    cg_max_steps: 5
    target_kl: 0.02
    gae_lambda: 0.95
    batch_size: 64
    net_arch: small
    activation_fn: relu
    ent_coef: 0.0005
    buffer_capacity: 61000
    reward_threshold: 350
    replay_strategy_threshold: 9.971485245676096
    epsilon: 0.35
    use_per: 1
    orthogonal_init: 0
    n_timesteps: 200000
    n_envs: 10
  comment: 'Best trial details: _number=24, state=1, _values=[-138.3224832], _datetime_start=2025-01-31
    07:33:04.116605, datetime_complete=2025-01-31 08:01:01.431171, _params={''n_steps'':
    64, ''gamma'': 0.9, ''learning_rate'': 0.004587560343239131, ''n_critic_updates'':
    10, ''cg_max_steps'': 5, ''target_kl'': 0.02, ''gae_lambda'': 0.95, ''batch_size'':
    64, ''net_arch'': ''small'', ''activation_fn'': ''relu'', ''ent_coef'': 0.0005,
    ''buffer_capacity'': 61000, ''reward_threshold'': 350.0, ''replay_strategy_threshold'':
    9.971485245676096, ''epsilon'': 0.35, ''use_per'': True, ''orthogonal_init'':
    False, ''n_timesteps'': 200000, ''n_envs'': 10}, _user_attrs={}, _system_attrs={''completed_rung_0'':
    -138.3224832}, intermediate_values={1: -138.3224832}, _distributions={''n_steps'':
    CategoricalDistribution(choices=(8, 16, 32, 64, 128, 256, 512, 1024, 2048)), ''gamma'':
    CategoricalDistribution(choices=(0.8, 0.85, 0.9, 0.95, 0.99)), ''learning_rate'':
    FloatDistribution(high=1.0, log=True, low=1e-05, step=None), ''n_critic_updates'':
    CategoricalDistribution(choices=(5, 10, 20, 25, 30)), ''cg_max_steps'': CategoricalDistribution(choices=(5,
    10, 20, 25, 30)), ''target_kl'': CategoricalDistribution(choices=(0.1, 0.05, 0.03,
    0.02, 0.01, 0.005, 0.001)), ''gae_lambda'': CategoricalDistribution(choices=(0.8,
    0.9, 0.92, 0.95, 0.98, 0.99, 1.0)), ''batch_size'': CategoricalDistribution(choices=(8,
    16, 32, 64, 128, 256, 512, 1024)), ''net_arch'': CategoricalDistribution(choices=(''small'',
    ''medium'')), ''activation_fn'': CategoricalDistribution(choices=(''tanh'', ''relu'')),
    ''ent_coef'': FloatDistribution(high=0.001, log=False, low=0.0, step=0.0001),
    ''buffer_capacity'': IntDistribution(high=100000, log=False, low=1000, step=1000),
    ''reward_threshold'': FloatDistribution(high=500.0, log=False, low=200.0, step=50.0),
    ''replay_strategy_threshold'': FloatDistribution(high=10.0, log=False, low=-10.0,
    step=None), ''epsilon'': FloatDistribution(high=0.9, log=False, low=0.1, step=0.05),
    ''use_per'': CategoricalDistribution(choices=(True, False)), ''orthogonal_init'':
    CategoricalDistribution(choices=(True, False)), ''n_timesteps'': IntDistribution(high=1000000,
    log=False, low=100000, step=100000), ''n_envs'': CategoricalDistribution(choices=(2,
    4, 6, 8, 10))}, _trial_id=24'
